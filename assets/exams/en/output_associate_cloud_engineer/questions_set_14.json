[
  {
    "question": "You are developing a new application and are looking for a Jenkins installation to build and deploy your source code. You want to automate the installation as quickly and easily as possible. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Deploy Jenkins through the Google Cloud Marketplace.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Create a new Compute Engine instance. Run the Jenkins executable.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Create a new Kubernetes Engine cluster. Create a deployment for the Jenkins image.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create an instance template with the Jenkins executable. Create a managed instance group with this template.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "You have downloaded and installed the gcloud command line interface (CLI) and have authenticated with your Google Account. Most of your Compute Engine instances in your project run in the europe-west1-d zone. You want to avoid having to specify this zone with each CLI command when managing these instances.What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Set the europe-west1-d zone as the default zone using the gcloud config subcommand.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "In the Settings page for Compute Engine under Default location, set the zone to europeג€\"west1-d.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "In the CLI installation directory, create a file called default.conf containing zone=europeג€\"west1ג€\"d.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create a Metadata entry on the Compute Engine page with key compute/zone and value europeג€\"west1ג€\"d.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "The core business of your company is to rent out construction equipment at large scale. All the equipment that is being rented out has been equipped with multiple sensors that send event information every few seconds. These signals can vary from engine status, distance traveled, fuel level, and more. Customers are billed based on the consumption monitored by these sensors. You expect high throughput `\" up to thousands of events per hour per device `\" and need to retrieve consistent data based on the time of the event. Storing and retrieving individual signals should be atomic. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Create a file in Cloud Storage per device and append new data to that file.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Create a file in Cloud Filestore per device and append new data to that file.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Ingest the data into Datastore. Store data in an entity group based on the device.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Ingest the data into Cloud Bigtable. Create a row key based on the event timestamp.",
        "correct": true,
        "why": ""
      }
    }
  },
  {
    "question": "You are asked to set up application performance monitoring on Google Cloud projects A, B, and C as a single pane of glass. You want to monitor CPU, memory, and disk. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Enable API and then share charts from project A, B, and C.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Enable API and then give the metrics.reader role to projects A, B, and C.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Enable API and then use default dashboards to view all projects in sequence.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Enable API, create a workspace under project A, and then add projects B and C.",
        "correct": true,
        "why": ""
      }
    }
  },
  {
    "question": "You created several resources in multiple Google Cloud projects. All projects are linked to different billing accounts. To better estimate future charges, you want to have a single visual representation of all costs incurred. You want to include new cost data as soon as possible. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Configure Billing Data Export to BigQuery and visualize the data in Data Studio.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Visit the Cost Table page to get a CSV export and visualize it using Data Studio.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Fill all resources in the Pricing Calculator to get an estimate of the monthly cost.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Use the Reports view in the Cloud Billing Console to view the desired cost information.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company has workloads running on Compute Engine and on-premises. The Google Cloud Virtual Private Cloud (VPC) is connected to your WAN over aVirtual Private Network (VPN). You need to deploy a new Compute Engine instance and ensure that no public Internet traffic can be routed to it. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Create the instance without a public IP address.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Create the instance with Private Google Access enabled.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Create a deny-all egress firewall rule on the VPC network.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create a route on the VPC to route all traffic to the instance over the VPN tunnel.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your team maintains the infrastructure for your organization. The current infrastructure requires changes. You need to share your proposed changes with the rest of the team. You want to follow Google's recommended best practices. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Use Deployment Manager templates to describe the proposed changes and store them in a Cloud Storage bucket.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Use Deployment Manager templates to describe the proposed changes and store them in Cloud Source Repositories.",
        "correct": true,
        "why": ""
      },
      "C": {
        "answer": "Apply the changes in a development environment, run gcloud compute instances list, and then save the output in a shared Storage bucket.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Apply the changes in a development environment, run gcloud compute instances list, and then save the output in Cloud Source Repositories.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "You have a Compute Engine instance hosting an application used between 9 AM and 6 PM on weekdays. You want to back up this instance daily for disaster recovery purposes. You want to keep the backups for 30 days. You want the Google-recommended solution with the least management overhead and the least number of services. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "1. Update your instances' metadata to add the following value: snapshotג€\"schedule: 0 1 * * * 2. Update your instances' metadata to add the following value: snapshotג€\"retention: 30",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "1. In the Cloud Console, go to the Compute Engine Disks page and select your instance's disk. 2. In the Snapshot Schedule section, select Create Schedule and configure the following parameters: - Schedule frequency: Daily - Start time: 1:00 AM ג€\" 2:00 AM - Autodelete snapshots after: 30 days",
        "correct": true,
        "why": ""
      },
      "C": {
        "answer": "1. Create a Cloud Function that creates a snapshot of your instance's disk. 2. Create a Cloud Function that deletes snapshots that are older than 30 days. 3. Use Cloud Scheduler to trigger both Cloud Functions daily at 1:00 AM.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "1. Create a bash script in the instance that copies the content of the disk to Cloud Storage. 2. Create a bash script in the instance that deletes data older than 30 days in the backup Cloud Storage bucket. 3. Configure the instance's crontab to execute these scripts daily at 1:00 AM.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your existing application running in Google Kubernetes Engine (GKE) consists of multiple pods running on four GKE n1`\"standard`\"2 nodes. You need to deploy additional pods requiring n2`\"highmem`\"16 nodes without any downtime. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Use gcloud container clusters upgrade. Deploy the new services.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Create a new Node Pool and specify machine type n2ג€\"highmemג€\"16. Deploy the new pods.",
        "correct": true,
        "why": ""
      },
      "C": {
        "answer": "Create a new cluster with n2ג€\"highmemג€\"16 nodes. Redeploy the pods and delete the old cluster.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create a new cluster with both n1ג€\"standardג€\"2 and n2ג€\"highmemג€\"16 nodes. Redeploy the pods and delete the old cluster.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "You have an application that uses Cloud Spanner as a database backend to keep current state information about users. Cloud Bigtable logs all events triggered by users. You export Cloud Spanner data to Cloud Storage during daily backups. One of your analysts asks you to join data from Cloud Spanner and CloudBigtable for specific users. You want to complete this ad hoc request as efficiently as possible. What should you do?",
    "multichoice": false,
    "alternatives": {
      "A": {
        "answer": "Create a dataflow job that copies data from Cloud Bigtable and Cloud Storage for specific users.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Create a dataflow job that copies data from Cloud Bigtable and Cloud Spanner for specific users.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Create a Cloud Dataproc cluster that runs a Spark job to extract data from Cloud Bigtable and Cloud Storage for specific users.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create two separate BigQuery external tables on Cloud Storage and Cloud Bigtable. Use the BigQuery console to join these tables through user fields, and apply appropriate filters.",
        "correct": true,
        "why": ""
      }
    }
  }
]