[
  {
    "question": "Your marketing department wants to send out a promotional email campaign. The development team wants to minimize direct operation management. They project a wide range of possible customer responses, from 100 to 500,000 click-through per day. The link leads to a simple website that explains the promotion and collects user information and preferences. Which infrastructure should you recommend? (Choose 2)",
    "alternatives": {
      "A": {
        "answer": "Use Google App Engine to serve the website and Google Cloud Datastore to store user data.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Use a Google Container Engine cluster to serve the website and store data to persistent disk.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Use a managed instance group to serve the website and Google Cloud Bigtable to store user data.",
        "correct": true,
        "why": ""
      },
      "D": {
        "answer": "Use a single Compute Engine virtual machine (VM) to host a web server, backend by Google Cloud SQL.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company just finished a rapid lift and shift to Google Compute Engine for your compute needs. You have another 9 months to design and deploy a more cloud-native solution. Specifically, you want a system that is no-ops and auto-scaling. Which two compute products should you choose? (Choose 2)",
    "alternatives": {
      "A": {
        "answer": "Compute Engine with containers",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Google Kubernetes Engine with containers",
        "correct": true,
        "why": ""
      },
      "C": {
        "answer": "Google App Engine Standard Environment",
        "correct": true,
        "why": ""
      },
      "D": {
        "answer": "Compute Engine with custom instance types",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "One of your primary business objectives is being able to trust the data stored in your application. You want to log all changes to the application data. How can you design your logging system to verify authenticity of your logs?",
    "alternatives": {
      "A": {
        "answer": "Write the log concurrently in the cloud and on premises",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "Use a SQL database and limit who can modify the log table",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Digitally sign each timestamp and log entry and store the signature",
        "correct": true,
        "why": ""
      },
      "D": {
        "answer": "Create a JSON dump of each log entry and store it in Google Cloud Storage",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company has a Google Workspace account and Google Cloud Organization. Some developers in the company have created Google Cloud projects outside of the Google Cloud Organization.You want to create an Organization structure that allows developers to create projects, but prevents them from modifying production projects. You want to manage policies for all projects centrally and be able to set more restrictive policies for production projects.You want to minimize disruption to users and developers when business needs change in the future. You want to follow Google-recommended practices. Now should you design the Organization structure?",
    "alternatives": {
      "A": {
        "answer": "1. Create a second Google Workspace account and Organization. 2. Grant all developers the Project Creator IAM role on the new Organization. 3. Move the developer projects into the new Organization. 4. Set the policies for all projects on both Organizations. 5. Additionally, set the production policies on the original Organization.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "1. Create a folder under the Organization resource named Production. 2. Grant all developers the Project Creator IAM role on the new Organization. 3. Move the developer projects into the new Organization. 4. Set the policies for all projects on the Organization. 5. Additionally, set the production policies on the Production folder.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "1. Create folders under the Organization resource named Development and Production. 2. Grant all developers the Project Creator IAM role on the Development folder. 3. Move the developer projects into the Development folder. 4. Set the policies for all projects on the Organization. 5. Additionally, set the production policies on the Production folder.",
        "correct": true,
        "why": ""
      },
      "D": {
        "answer": "1. Designate the Organization for production projects only. 2. Ensure that developers do not have the Project Creator IAM role on the Organization. 3. Create development projects outside of the Organization using the developer Google Workspace accounts. 4. Set the policies for all projects on the Organization. 5. Additionally, set the production policies on the individual production projects.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company has an application running on Compute Engine that allows users to play their favorite music. There are a fixed number of instances. Files are stored in Cloud Storage, and data is streamed directly to users. Users are reporting that they sometimes need to attempt to play popular songs multiple times before they are successful. You need to improve the performance of the application. What should you do?",
    "alternatives": {
      "A": {
        "answer": "1. Mount the Cloud Storage bucket using gcsfuse on all backend Compute Engine instances. 2. Serve music files directly from the backend Compute Engine instance.",
        "correct": false,
        "why": ""
      },
      "B": {
        "answer": "1. Create a Cloud Filestore NFS volume and attach it to the backend Compute Engine instances. 2. Download popular songs in Cloud Filestore. 3. Serve music files directly from the backend Compute Engine instance.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "1. Copy popular songs into CloudSQL as a blob. 2. Update application code to retrieve data from CloudSQL when Cloud Storage is overloaded.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "1. Create a managed instance group with Compute Engine instances. 2. Create a global load balancer and configure it with two backends: ג—‹ Managed instance group ג—‹ Cloud Storage bucket 3. Enable Cloud CDN on the bucket backend.",
        "correct": true,
        "why": ""
      }
    }
  },
  {
    "question": "The operations team in your company wants to save Cloud VPN log events for one year. You need to configure the cloud infrastructure to save the logs. What should you do?",
    "alternatives": {
      "A": {
        "answer": "Set up a filter in Cloud Logging and a Cloud Storage bucket as an export target for the logs you want to save.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Enable the Compute Engine API, and then enable logging on the firewall rules that match the traffic you want to save.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Set up a Cloud Logging Dashboard titled Cloud VPN Logs, and then add a chart that queries for the VPN metrics over a one-year time period.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Set up a filter in Cloud Logging and a topic in Pub/Sub to publish the logs.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "You are working with a data warehousing team that performs data analysis. The team needs to process data from external partners, but the data contains personally identifiable information (PII). You need to process and store the data without storing any of the PIIE data. What should you do?",
    "alternatives": {
      "A": {
        "answer": "Create a Dataflow pipeline to retrieve the data from the external sources. As part of the pipeline, use the Cloud Data Loss Prevention (Cloud DLP) API to remove any PII data. Store the result in BigQuery.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Create a Dataflow pipeline to retrieve the data from the external sources. As part of the pipeline, store all non-PII data in BigQuery and store all PII data in a Cloud Storage bucket that has a retention policy set.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Ask the external partners to upload all data on Cloud Storage. Configure Bucket Lock for the bucket. Create a Dataflow pipeline to read the data from the bucket. As part of the pipeline, use the Cloud Data Loss Prevention (Cloud DLP) API to remove any PII data. Store the result in BigQuery.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Ask the external partners to import all data in your BigQuery dataset. Create a dataflow pipeline to copy the data into a new table. As part of the Dataflow bucket, skip all data in columns that have PII data",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "You want to allow your operations team to store logs from all the production projects in your Organization, without including logs from other projects. All of the production projects are contained in a folder. You want to ensure that all logs for existing and new production projects are captured automatically. What should you do?",
    "alternatives": {
      "A": {
        "answer": "Create an aggregated export on the Production folder. Set the log sink to be a Cloud Storage bucket in an operations project.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Create an aggregated export on the Organization resource. Set the log sink to be a Cloud Storage bucket in an operations project.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Create log exports in the production projects. Set the log sinks to be a Cloud Storage bucket in an operations project.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create log exports in the production projects. Set the log sinks to be BigQuery datasets in the production projects, and grant IAM access to the operations team to run queries on the datasets.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company has an application that is running on multiple instances of Compute Engine. It generates 1 TB per day of logs. For compliance reasons, the logs need to be kept for at least two years. The logs need to be available for active query for 30 days. After that, they just need to be retained for audit purposes. You want to implement a storage solution that is compliant, minimizes costs, and follows Google-recommended practices. What should you do?",
    "alternatives": {
      "A": {
        "answer": "1. Install a Cloud Logging agent on all instances. 2. Create a sink to export logs into a regional Cloud Storage bucket. 3. Create an Object Lifecycle rule to move files into a Coldline Cloud Storage bucket after one month. 4. Configure a retention policy at the bucket level using bucket lock.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "1. Write a daily cron job, running on all instances, that uploads logs into a Cloud Storage bucket. 2. Create a sink to export logs into a regional Cloud Storage bucket. 3. Create an Object Lifecycle rule to move files into a Coldline Cloud Storage bucket after one month.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "1. Install a Cloud Logging agent on all instances. 2. Create a sink to export logs into a partitioned BigQuery table. 3. Set a time_partitioning_expiration of 30 days.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "1. Create a daily cron job, running on all instances, that uploads logs into a partitioned BigQuery table. 2. Set a time_partitioning_expiration of 30 days.",
        "correct": false,
        "why": ""
      }
    }
  },
  {
    "question": "Your company has just recently activated Cloud Identity to manage users. The Google Cloud Organization has been configured as well. The security team needs to secure projects that will be part of the Organization. They want to prohibit IAM users outside the domain from gaining permissions from now on. What should they do?",
    "alternatives": {
      "A": {
        "answer": "Configure an organization policy to restrict identities by domain.",
        "correct": true,
        "why": ""
      },
      "B": {
        "answer": "Configure an organization policy to block creation of service accounts.",
        "correct": false,
        "why": ""
      },
      "C": {
        "answer": "Configure Cloud Scheduler to trigger a Cloud Function every hour that removes all users that don't belong to the Cloud Identity domain from all projects.",
        "correct": false,
        "why": ""
      },
      "D": {
        "answer": "Create a technical user (e.g., crawler@yourdomain.com), and give it the project owner role at root organization level. Write a bash script that: ¢ Lists all the IAM rules of all projects within the organization. ¢ Deletes all users that do not belong to the company domain. Create a Compute Engine instance in a project within the Organization and configure gcloud to be executed with technical user credentials. Configure a cron job that executes the bash script every hour.",
        "correct": false,
        "why": ""
      }
    }
  }
]